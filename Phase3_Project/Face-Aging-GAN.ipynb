{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " Face-Aging-GAN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTjXB5YsM4zQ",
        "colab_type": "code",
        "outputId": "da20c289-b5f9-4aa3-ab7c-fe2faa706979",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/Drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1fOdpMwNT7L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load model checkpoints\n",
        "urls = [\"https://www.dropbox.com/s/ud0xpk0aageatmt/faces-BA-100.h5?dl=0\", \"https://www.dropbox.com/s/mffhew71g0ecvjg/faces-AB-100.h5?dl=0\", \"https://www.dropbox.com/s/u12v9c3kawbl33s/faces-100.h5?dl=0\"]\n",
        "\n",
        "def download_from_dropbox(urls):\n",
        "    for url in urls:\n",
        "      url = url.split(\"?\")[0].replace(\"dropbox\", \"dl.dropboxusercontent\")\n",
        "      os.system(f'wget {url}')\n",
        "  \n",
        "download_from_dropbox(urls)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SZCYSed6TmM",
        "colab_type": "text"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKxrNUn-NWzD",
        "colab_type": "code",
        "outputId": "1a74b765-eac4-471d-a99b-ffcc6150e082",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "source": [
        "!pip install git+https://www.github.com/keras-team/keras-contrib.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://www.github.com/keras-team/keras-contrib.git\n",
            "  Cloning https://www.github.com/keras-team/keras-contrib.git to /tmp/pip-req-build-i188p13c\n",
            "  Running command git clone -q https://www.github.com/keras-team/keras-contrib.git /tmp/pip-req-build-i188p13c\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from keras-contrib==2.0.8) (2.2.4)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (3.13)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.1.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.12.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.3.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (2.8.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.16.4)\n",
            "Building wheels for collected packages: keras-contrib\n",
            "  Building wheel for keras-contrib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-contrib: filename=keras_contrib-2.0.8-cp36-none-any.whl size=101066 sha256=6fabe3ed5a4c4e027fc4712049a5eef6c4d4c3a6579814d7e01b242c28be2e9b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-681o5i2u/wheels/11/27/c8/4ed56de7b55f4f61244e2dc6ef3cdbaff2692527a2ce6502ba\n",
            "Successfully built keras-contrib\n",
            "Installing collected packages: keras-contrib\n",
            "Successfully installed keras-contrib-2.0.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIHj5DbWNiC3",
        "colab_type": "code",
        "outputId": "e42dcdaf-97cb-46a2-9f6f-320ea215e332",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras_contrib.layers.normalization.instancenormalization import InstanceNormalization\n",
        "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Concatenate, Lambda, Add\n",
        "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
        "from keras.layers.convolutional import UpSampling2D, Conv2D, Conv2DTranspose\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.activations import relu, tanh\n",
        "from keras.models import Sequential, Model\n",
        "from keras.optimizers import Adam\n",
        "from keras import backend as K\n",
        "from glob import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime\n",
        "import scipy\n",
        "import scipy.misc\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow.contrib.slim as slim\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import copy\n",
        "import math\n",
        "import cv2\n",
        "\n",
        "np.random.seed(42)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6zisS0x6dIc",
        "colab_type": "text"
      },
      "source": [
        "## Get Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDGObZSs4xIC",
        "colab_type": "code",
        "outputId": "352a8b0a-4932-441e-b844-90b7bbe7f0bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def download():\n",
        "  url = 'https://dl.dropboxusercontent.com/s/1i2h7orwm2cx8s0/UTKFace.tar.gz'\n",
        "  fpath = 'UTKFace.tar.gz'\n",
        "  filename = fpath.split('/')[-1]\n",
        "  if not os.path.isfile(fpath):\n",
        "    os.system(f'wget {url}')\n",
        "    os.system(f'tar xzf {filename}')\n",
        "  else:\n",
        "    print(\"Data already present\")\n",
        "    \n",
        "\n",
        "def copy_imgs_young(fpath, data_path):\n",
        "  low = 18\n",
        "  high = 25\n",
        "  final_path_train = data_path + \"/trainA\"\n",
        "  final_path_test = data_path + \"/testA\"\n",
        "  if not os.path.isdir(final_path_train):\n",
        "    os.makedirs(final_path_train)\n",
        "  if not os.path.isdir(final_path_test):\n",
        "    os.makedirs(final_path_test)\n",
        "  allowed_files = []\n",
        "  for fname in tqdm(glob(fpath+\"/*.jpg\")):\n",
        "    age = int(fname.split('/')[-1].split('_')[0])\n",
        "    if age >= low and age <= high:\n",
        "      allowed_files.append(fname)\n",
        "      \n",
        "  allowed_files.sort()\n",
        "  train_len = int(0.8*len(allowed_files))\n",
        "  for fname in tqdm(allowed_files[:train_len]):\n",
        "      os.system(f'cp {fname} {final_path_train}/')\n",
        "  for fname in tqdm(allowed_files[train_len:]):\n",
        "      os.system(f'cp {fname} {final_path_test}/')\n",
        "      \n",
        "def copy_imgs_old(fpath, data_path):\n",
        "  low = 50\n",
        "  high = 60\n",
        "  final_path_train = data_path + \"/trainB\"\n",
        "  final_path_test = data_path + \"/testB\"\n",
        "  if not os.path.isdir(final_path_train):\n",
        "    os.makedirs(final_path_train)\n",
        "  if not os.path.isdir(final_path_test):\n",
        "    os.makedirs(final_path_test)\n",
        "  allowed_files = []\n",
        "  \n",
        "  for fname in tqdm(glob(fpath+\"/*.jpg\")):\n",
        "    age = int(fname.split('/')[-1].split('_')[0])\n",
        "    if age >= low and age <= high:\n",
        "      allowed_files.append(fname)\n",
        "  \n",
        "  allowed_files.sort()\n",
        "  train_len = int(0.8*len(allowed_files))\n",
        "  for fname in tqdm(allowed_files[:train_len]):\n",
        "      os.system(f'cp {fname} {final_path_train}/')\n",
        "  for fname in tqdm(allowed_files[train_len:]):\n",
        "      os.system(f'cp {fname} {final_path_test}/')\n",
        "      \n",
        "def prepare_dataset():\n",
        "  download()\n",
        "  copy_imgs_young('UTKFace', 'datasets/faces')\n",
        "  copy_imgs_old('UTKFace', 'datasets/faces')\n",
        "  \n",
        "  \n",
        "prepare_dataset()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 23708/23708 [00:00<00:00, 846811.71it/s]\n",
            "100%|██████████| 2723/2723 [00:28<00:00, 94.17it/s]\n",
            "100%|██████████| 681/681 [00:07<00:00, 94.16it/s]\n",
            "100%|██████████| 23708/23708 [00:00<00:00, 892626.20it/s]\n",
            "100%|██████████| 2073/2073 [00:21<00:00, 94.77it/s]\n",
            "100%|██████████| 519/519 [00:05<00:00, 94.91it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20A0DxYP6PhM",
        "colab_type": "text"
      },
      "source": [
        "## Model declaration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Muel1elo49jj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DataLoader():\n",
        "  def __init__(self, dataset_name, img_res=(256, 256)):\n",
        "    self.dataset_name = dataset_name\n",
        "    self.img_res = img_res\n",
        "    self.dataset_root_path = \"datasets\"\n",
        "\n",
        "  def load_data(self, domain, batch_size=1, is_testing=False):\n",
        "    data_type = \"train%s\" % domain if not is_testing else \"test%s\" % domain\n",
        "    path = glob('./datasets/%s/%s/*' % (self.dataset_name, data_type))\n",
        "\n",
        "    batch_images = np.random.choice(path, size=batch_size)\n",
        "\n",
        "    imgs = []\n",
        "    for img_path in batch_images:\n",
        "      img = self.imread(img_path)\n",
        "      if not is_testing:\n",
        "        img = cv2.resize(img, self.img_res)\n",
        "\n",
        "        if np.random.random() > 0.5:\n",
        "          img = np.fliplr(img)\n",
        "      else:\n",
        "        img = cv2.resize(img, self.img_res)\n",
        "      imgs.append(img)\n",
        "\n",
        "    imgs = np.array(imgs)/127.5 - 1.\n",
        "\n",
        "    return imgs\n",
        "\n",
        "  def load_batch(self, batch_size=1, is_testing=False):\n",
        "    data_type = \"train\" if not is_testing else \"val\"\n",
        "    path_A = glob(f'./{self.dataset_root_path}/%s/%sA/*' % (self.dataset_name, data_type))\n",
        "    path_B = glob(f'./{self.dataset_root_path}/%s/%sB/*' % (self.dataset_name, data_type))\n",
        "\n",
        "    self.n_batches = int(min(len(path_A), len(path_B)) / batch_size)\n",
        "    total_samples = self.n_batches * batch_size\n",
        "\n",
        "    # Sample n_batches * batch_size from each path list so that model sees all\n",
        "    # samples from both domains\n",
        "    path_A = np.random.choice(path_A, total_samples, replace=False)\n",
        "    path_B = np.random.choice(path_B, total_samples, replace=False)\n",
        "\n",
        "    for i in range(self.n_batches-1):\n",
        "      batch_A = path_A[i*batch_size:(i+1)*batch_size]\n",
        "      batch_B = path_B[i*batch_size:(i+1)*batch_size]\n",
        "      imgs_A, imgs_B = [], []\n",
        "      for img_A, img_B in zip(batch_A, batch_B):\n",
        "        img_A = self.imread(img_A)\n",
        "        img_B = self.imread(img_B)\n",
        "\n",
        "        img_A = cv2.resize(img_A, self.img_res)\n",
        "        img_B = cv2.resize(img_B, self.img_res)\n",
        "\n",
        "        if not is_testing and np.random.random() > 0.5:\n",
        "            img_A = np.fliplr(img_A)\n",
        "            img_B = np.fliplr(img_B)\n",
        "\n",
        "        imgs_A.append(img_A)\n",
        "        imgs_B.append(img_B)\n",
        "\n",
        "      imgs_A = np.array(imgs_A)/127.5 - 1.\n",
        "      imgs_B = np.array(imgs_B)/127.5 - 1.\n",
        "\n",
        "      yield imgs_A, imgs_B\n",
        "\n",
        "  def load_img(self, path):\n",
        "    img = self.imread(path)\n",
        "    img = cv2.resize(img, self.img_res)\n",
        "    img = img/127.5 - 1.\n",
        "    return img[np.newaxis, :, :, :]\n",
        "\n",
        "  def imread(self, path):\n",
        "    img = cv2.imread(path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB).astype(np.float)\n",
        "    return img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UYoD7cCpgdY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CycleGAN():\n",
        "  def __init__(self, save_path='train', output_img_path='/Drive/My Drive/facegan/images', combined_weights_path=None):\n",
        "    # Input shape\n",
        "    self.img_rows = 256\n",
        "    self.img_cols = 256\n",
        "    self.channels = 3\n",
        "    self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
        "\n",
        "    # Configure data loader\n",
        "    self.dataset_name = 'faces'\n",
        "    self.data_loader = DataLoader(dataset_name=self.dataset_name,\n",
        "                    img_res=(self.img_rows, self.img_cols))\n",
        "    \n",
        "    self.save_path = save_path\n",
        "    self.output_img_path = output_img_path\n",
        "\n",
        "\n",
        "    # Calculate output shape of D (PatchGAN)\n",
        "    patch = int(self.img_rows / 2**4)\n",
        "    patch *= 2  # hack to get the shape 32,32,1. todo: check\n",
        "    self.disc_patch = (patch, patch, 1)\n",
        "\n",
        "    # Number of filters in the first layer of G and D\n",
        "    self.gf = 64\n",
        "    self.df = 64\n",
        "\n",
        "    # Loss weights\n",
        "    self.lambda_cycle = 10.0          # Cycle-consistency loss\n",
        "    self.lambda_id = 0.1 * self.lambda_cycle  # Identity loss\n",
        "\n",
        "    self.lr_init = 0.0002\n",
        "    self.epoch_step = 100\n",
        "    \n",
        "    optimizer = Adam(self.lr_init, 0.5)\n",
        "\n",
        "    # Build and compile the discriminators\n",
        "    self.d_A = self.build_discriminator()\n",
        "    self.d_B = self.build_discriminator()\n",
        "    print(\"Summary Discriminator:\")\n",
        "    print(self.d_A.summary())\n",
        "    self.d_A.compile(loss='mse',\n",
        "      optimizer=optimizer,\n",
        "      metrics=['accuracy'])\n",
        "    self.d_B.compile(loss='mse',\n",
        "      optimizer=optimizer,\n",
        "      metrics=['accuracy'])\n",
        "\n",
        "    #-------------------------\n",
        "    # Construct Computational\n",
        "    #   Graph of Generators\n",
        "    #-------------------------\n",
        "\n",
        "    # Build the generators\n",
        "    self.g_AB = self.build_generator()\n",
        "    self.g_BA = self.build_generator()\n",
        "    print(\"Summary Generator:\")\n",
        "    print(self.g_AB.summary())\n",
        "\n",
        "    # Input images from both domains\n",
        "    img_A = Input(shape=self.img_shape)\n",
        "    img_B = Input(shape=self.img_shape)\n",
        "\n",
        "    # Translate images to the other domain\n",
        "    fake_B = self.g_AB(img_A)\n",
        "    fake_A = self.g_BA(img_B)\n",
        "    # Translate images back to original domain\n",
        "    reconstr_A = self.g_BA(fake_B)\n",
        "    reconstr_B = self.g_AB(fake_A)\n",
        "    # Identity mapping of images\n",
        "    img_A_id = self.g_BA(img_A)\n",
        "    img_B_id = self.g_AB(img_B)\n",
        "\n",
        "    # For the combined model we will only train the generators\n",
        "    self.d_A.trainable = False\n",
        "    self.d_B.trainable = False\n",
        "\n",
        "    # Discriminators determines validity of translated images\n",
        "    valid_A = self.d_A(fake_A)\n",
        "    valid_B = self.d_B(fake_B)\n",
        "\n",
        "    # Combined model trains generators to fool discriminators\n",
        "    self.combined = Model(inputs=[img_A, img_B],\n",
        "                outputs=[ valid_A, valid_B,\n",
        "                    reconstr_A, reconstr_B,\n",
        "                    img_A_id, img_B_id ])\n",
        "    \n",
        "    if combined_weights_path is not None:\n",
        "        self.combined.load_weights(combined_weights_path)\n",
        "    \n",
        "    self.combined.compile(loss=['mse', 'mse',\n",
        "                  'mae', 'mae',\n",
        "                  'mae', 'mae'],\n",
        "              loss_weights=[  1, 1,\n",
        "                      self.lambda_cycle, self.lambda_cycle,\n",
        "                      self.lambda_id, self.lambda_id ],\n",
        "              optimizer=optimizer)\n",
        "\n",
        "  def build_generator(self, name=\"generator\"):\n",
        "    gf_dim=self.gf\n",
        "    output_c_dim=self.channels\n",
        "    def conv2D(input_,\n",
        "               output_dim, \n",
        "               ks=4, \n",
        "               s=2, \n",
        "               stddev=0.02, \n",
        "               padding='SAME', \n",
        "               activation=False, \n",
        "               instance_norm=False, \n",
        "               name=\"conv2d\", \n",
        "               act_name=\"relu\",\n",
        "               activation_tanh=True,\n",
        "               inst_norm_name=\"bn\"):\n",
        "\n",
        "      if activation_tanh:\n",
        "        x = Conv2D(\n",
        "          output_dim, \n",
        "          kernel_size=(ks, ks), \n",
        "          strides=s, \n",
        "          padding=padding, \n",
        "          kernel_initializer=tf.truncated_normal_initializer(stddev=stddev),\n",
        "          name=name,\n",
        "          activation='tanh',\n",
        "          use_bias=False)(input_)\n",
        "      elif activation:\n",
        "        x = Conv2D(\n",
        "            output_dim, \n",
        "            kernel_size=(ks, ks), \n",
        "            strides=s, \n",
        "            padding=padding, \n",
        "            kernel_initializer=tf.truncated_normal_initializer(stddev=stddev),\n",
        "            name=name,\n",
        "            activation='relu',\n",
        "            use_bias=False)(input_)\n",
        "      else:\n",
        "        x = Conv2D(\n",
        "            output_dim, \n",
        "            kernel_size=(ks, ks), \n",
        "            strides=s, \n",
        "            padding=padding, \n",
        "            kernel_initializer=tf.truncated_normal_initializer(stddev=stddev),\n",
        "            name=name,\n",
        "            use_bias=False)(input_)\n",
        "      if instance_norm:\n",
        "        x = InstanceNormalization(name=inst_norm_name)(x)\n",
        "\n",
        "      return x\n",
        "\n",
        "    def deconv2d(input_, output_dim, ks=4, s=2, stddev=0.02, name=\"deconv2d\"):\n",
        "      x = Conv2DTranspose(\n",
        "          output_dim, \n",
        "          kernel_size=(ks, ks), \n",
        "          strides=s, \n",
        "          padding='SAME', \n",
        "          kernel_initializer=tf.truncated_normal_initializer(stddev=stddev),\n",
        "          name=name,\n",
        "          use_bias=False)(input_)\n",
        "\n",
        "      return x\n",
        "\n",
        "    def residule_block(x, dim, ks=3, s=1, name='res'):\n",
        "        p = int((ks - 1) / 2)\n",
        "        y = Lambda(lambda lx: tf.pad(lx, [[0, 0], [p, p], [p, p], [0, 0]], \"REFLECT\") )(x)\n",
        "        y = conv2D(y,dim,ks=ks,s=s,padding=\"VALID\",name=name+\"_c1\",activation=True,instance_norm=True,inst_norm_name=name+\"_bn1\")\n",
        "        y = Lambda(lambda x: tf.pad(x, [[0, 0], [p, p], [p, p], [0, 0]], \"REFLECT\"))(y)\n",
        "        y = conv2D(y,dim,ks=ks,s=s,padding=\"VALID\",name=name+\"_c2\",activation=False,instance_norm=True,inst_norm_name=name+\"_bn2\")\n",
        "        a = Add()([y,x])\n",
        "        return a           # 1/2을 안해도 되나??? 뒤에 노말라이즈해서 상관없는건가....\n",
        "\n",
        "    # Justin Johnson's model from https://github.com/jcjohnson/fast-neural-style/\n",
        "    # The network with 9 blocks consists of: c7s1-32, d64, d128, R128, R128, R128,\n",
        "    # R128, R128, R128, R128, R128, R128, u64, u32, c7s1-3\n",
        "    \n",
        "    inp = Input(shape=self.img_shape)\n",
        "\n",
        "    c0 = Lambda(lambda x: tf.pad(x, [[0, 0], [3, 3], [3, 3], [0, 0]], \"REFLECT\") )(inp)\n",
        "\n",
        "\n",
        "    c1 = conv2D(c0,gf_dim,ks=7,s=1,padding=\"VALID\",name=\"g_e1_c\",activation=True,instance_norm=True,inst_norm_name=name+\"g_e1_bn\", act_name=\"g_e1_relu\")\n",
        "    c2 = conv2D(c1,gf_dim*2,ks=3,s=2,name=\"g_e2_c\",activation=True,instance_norm=True,inst_norm_name=name+\"g_e2_bn\", act_name=\"g_e2_relu\")\n",
        "    c3 = conv2D(c2,gf_dim*4,ks=3,s=2,name=\"g_e3_c\",activation=True,instance_norm=True,inst_norm_name=name+\"g_e3_bn\", act_name=\"g_e3_relu\")  # 64x64\n",
        "\n",
        "    # define G network with 9 resnet blocks\n",
        "    # 총 cnn 18층.\n",
        "    r1 = residule_block(c3, gf_dim*4, name='g_r1')\n",
        "    r2 = residule_block(r1, gf_dim*4, name='g_r2')\n",
        "    r3 = residule_block(r2, gf_dim*4, name='g_r3')\n",
        "    r4 = residule_block(r3, gf_dim*4, name='g_r4')\n",
        "    r5 = residule_block(r4, gf_dim*4, name='g_r5')\n",
        "    r6 = residule_block(r5, gf_dim*4, name='g_r6')\n",
        "    r7 = residule_block(r6, gf_dim*4, name='g_r7')\n",
        "    r8 = residule_block(r7, gf_dim*4, name='g_r8')\n",
        "    r9 = residule_block(r8, gf_dim*4, name='g_r9')\n",
        "\n",
        "    d1 = deconv2d(r9, gf_dim*2, 3, 2, name='g_d1_dc')\n",
        "    d1 = InstanceNormalization(name='g_d1_bn')(d1)\n",
        "    d1 = Lambda(lambda x: relu(x))(d1)\n",
        "\n",
        "    d2 = deconv2d(d1, gf_dim, 3, 2, name='g_d2_dc')\n",
        "    d2 = InstanceNormalization(name='g_d2_bn')(d2)\n",
        "    d2 = Lambda(lambda x: relu(x))(d2)\n",
        "\n",
        "    d2 = Lambda(lambda x: tf.pad(x, [[0, 0], [3, 3], [3, 3], [0, 0]], \"REFLECT\"))(d2)\n",
        "\n",
        "    pred = conv2D(d2,output_c_dim,ks=7,s=1,padding=\"VALID\",name=\"g_pred_c\",activation=False,instance_norm=False,activation_tanh=True)\n",
        "\n",
        "    return Model(inp, pred)\n",
        "\n",
        "  def build_discriminator(self, name=\"discriminator\"):\n",
        "    df_dim=self.df\n",
        "    def conv2D(input_,\n",
        "               output_dim, \n",
        "               ks=4, \n",
        "               s=2, \n",
        "               stddev=0.02, \n",
        "               padding='SAME', \n",
        "               activation=False, \n",
        "               instance_norm=False, \n",
        "               name=\"conv2d\", \n",
        "               act_name=\"lrelu\",\n",
        "               inst_norm_name=\"bn\"):\n",
        "\n",
        "      x = Conv2D(\n",
        "          output_dim, \n",
        "          kernel_size=(ks, ks), \n",
        "          strides=s, \n",
        "          padding=padding, \n",
        "          kernel_initializer=tf.truncated_normal_initializer(stddev=stddev),\n",
        "          name=name,\n",
        "          use_bias=False)(input_)\n",
        "      if activation:\n",
        "        x = LeakyReLU(alpha=0.2,name=act_name)(x)\n",
        "      if instance_norm:\n",
        "        x = InstanceNormalization(name=inst_norm_name)(x)\n",
        "\n",
        "      return x\n",
        "\n",
        "    inp = Input(shape=self.img_shape)\n",
        "    h0 = conv2D(inp, df_dim, name='d_h0_conv',activation=True)\n",
        "    # h0 = lrelu(conv2d(image, df_dim, name='d_h0_conv'))\n",
        "    # h0 is (128 x 128 x self.df_dim)\n",
        "\n",
        "    h1 = conv2D(h0, df_dim*2, name='d_h1_conv',activation=True, instance_norm=True, inst_norm_name='d_bn1', act_name='d_lrelu1')\n",
        "    # h1 = lrelu(instance_norm(conv2d(h0, df_dim*2, name='d_h1_conv'), 'd_bn1'))\n",
        "    # h1 is (64 x 64 x self.df_dim*2)\n",
        "\n",
        "    h2 = conv2D(h1, df_dim*4, name='d_h2_conv',activation=True, instance_norm=True, inst_norm_name='d_bn2', act_name='d_lrelu2')\n",
        "    # h2 = lrelu(instance_norm(conv2d(h1, df_dim*4, name='d_h2_conv'), 'd_bn2'))\n",
        "    # h2 is (32x 32 x self.df_dim*4)\n",
        "\n",
        "    h3 = conv2D(h2, df_dim*8, name='d_h3_conv', s=1, activation=True, instance_norm=True, inst_norm_name='d_bn3', act_name='d_lrelu3')\n",
        "    # h3 = lrelu(instance_norm(conv2d(h2, df_dim*8, s=1, name='d_h3_conv'), 'd_bn3'))\n",
        "    # h3 is (32 x 32 x self.df_dim*8)\n",
        "\n",
        "    h4 = conv2D(h3, 1, name='d_h3_pred', s=1, activation=False, instance_norm=False)\n",
        "    # h4 = conv2d(h3, 1, s=1, name='d_h3_pred')\n",
        "    # h4 is (32 x 32 x 1)\n",
        "\n",
        "    return Model(inp, h4)\n",
        "\n",
        "  def train(self, epochs, batch_size=1, sample_interval=500, init_epoch=0):\n",
        "\n",
        "    start_time = datetime.datetime.now()\n",
        "\n",
        "    # Adversarial loss ground truths\n",
        "    valid = np.ones((batch_size,) + self.disc_patch)\n",
        "    fake = np.zeros((batch_size,) + self.disc_patch)\n",
        "\n",
        "    for epoch in range(init_epoch, epochs):\n",
        "      lr = self.lr_init if epoch < self.epoch_step else self.lr_init*(epochs-epoch)/(epochs-self.epoch_step)    # lr이 작아짐. 100에폭이 지나면.\n",
        "      for batch_i, (imgs_A, imgs_B) in enumerate(self.data_loader.load_batch(batch_size)):\n",
        "                \n",
        "        K.set_value(self.d_A.optimizer.lr, lr)\n",
        "        K.set_value(self.d_B.optimizer.lr, lr)\n",
        "        K.set_value(self.combined.optimizer.lr, lr)\n",
        "\n",
        "        # ----------------------\n",
        "        #  Train Discriminators\n",
        "        # ----------------------\n",
        "\n",
        "        # Translate images to opposite domain\n",
        "        fake_B = self.g_AB.predict(imgs_A)\n",
        "        fake_A = self.g_BA.predict(imgs_B)\n",
        "        \n",
        "        # Train the discriminators (original images = real / translated = Fake)\n",
        "        dA_loss_real = self.d_A.train_on_batch(imgs_A, valid)\n",
        "        dA_loss_fake = self.d_A.train_on_batch(fake_A, fake)\n",
        "        dA_loss = 0.5 * np.add(dA_loss_real, dA_loss_fake)\n",
        "\n",
        "        dB_loss_real = self.d_B.train_on_batch(imgs_B, valid)\n",
        "        dB_loss_fake = self.d_B.train_on_batch(fake_B, fake)\n",
        "        dB_loss = 0.5 * np.add(dB_loss_real, dB_loss_fake)\n",
        "\n",
        "        # Total disciminator loss\n",
        "        d_loss = 0.5 * np.add(dA_loss, dB_loss)\n",
        "\n",
        "\n",
        "        # ------------------\n",
        "        #  Train Generators\n",
        "        # ------------------\n",
        "\n",
        "        # Train the generators\n",
        "        g_loss = self.combined.train_on_batch([imgs_A, imgs_B],\n",
        "                            [valid, valid,\n",
        "                            imgs_A, imgs_B,\n",
        "                            imgs_A, imgs_B])\n",
        "\n",
        "        elapsed_time = datetime.datetime.now() - start_time\n",
        "\n",
        "        # Plot the progress\n",
        "        print (\"[Epoch %d/%d] [Batch %d/%d] [D loss: %f, acc: %3d%%] [G loss: %05f, adv: %05f, recon: %05f, id: %05f] time: %s \" \\\n",
        "                                    % ( epoch, epochs,\n",
        "                                      batch_i, self.data_loader.n_batches,\n",
        "                                      d_loss[0], 100*d_loss[1],\n",
        "                                      g_loss[0],\n",
        "                                      np.mean(g_loss[1:3]),\n",
        "                                      np.mean(g_loss[3:5]),\n",
        "                                      np.mean(g_loss[5:6]),\n",
        "                                      elapsed_time))\n",
        "\n",
        "        # If at save interval => save generated image samples\n",
        "        if batch_i % sample_interval == 0:\n",
        "          self.sample_images(epoch, batch_i)\n",
        "          self.save_model(epoch)\n",
        "\n",
        "          \n",
        "  def save_model(self, epoch):\n",
        "    print(\"Saving model now\")\n",
        "    if not os.path.isdir(self.save_path):\n",
        "      os.makedirs(self.save_path)\n",
        "    # for further training - save with\n",
        "    self.combined.save_weights(self.save_path+'/%s-%d.h5' % (self.dataset_name, epoch))\n",
        "    \n",
        "    # reload with\n",
        "    # self.combined.load_weights('train/%s-%d.h5' % (self.dataset_name, epoch))\n",
        "\n",
        "    # to generate images - save with\n",
        "    self.g_AB.save_weights(self.save_path+'/%s-AB-%d.h5' % (self.dataset_name, epoch))\n",
        "    self.g_BA.save_weights(self.save_path+'/%s-BA-%d.h5' % (self.dataset_name, epoch))\n",
        "    \n",
        "    # load with\n",
        "    # self.g_AB.load_weights('train/%s-AB-%d.h5' % (self.dataset_name, epoch))\n",
        "    # self.g_BA.load_weights('train/%s-BA-%d.h5' % (self.dataset_name, epoch))\n",
        "    \n",
        "  def sample_images(self, epoch, batch_i):\n",
        "    os.makedirs(self.output_img_path+'/%s' % self.dataset_name, exist_ok=True)\n",
        "    \n",
        "    print(\"Loading weights\")\n",
        "    self.g_AB.load_weights('faces-AB-100.h5')\n",
        "    self.g_BA.load_weights('faces-BA-100.h5')\n",
        "    print(\"Done loading\")\n",
        "    \n",
        "    r, c = 2, 3\n",
        "\n",
        "    imgs_A = self.data_loader.load_data(domain=\"A\", batch_size=1, is_testing=True)\n",
        "    imgs_B = self.data_loader.load_data(domain=\"B\", batch_size=1, is_testing=True)\n",
        "\n",
        "    # Demo (for GIF)\n",
        "    #imgs_A = self.data_loader.load_img('datasets/apple2orange/testA/n07740461_1541.jpg')\n",
        "    #imgs_B = self.data_loader.load_img('datasets/apple2orange/testB/n07749192_4241.jpg')\n",
        "\n",
        "    # Translate images to the other domain\n",
        "    fake_B = self.g_AB.predict(imgs_A)\n",
        "    fake_A = self.g_BA.predict(imgs_B)\n",
        "    # Translate back to original domain\n",
        "    reconstr_A = self.g_BA.predict(fake_B)\n",
        "    reconstr_B = self.g_AB.predict(fake_A)\n",
        "    \n",
        "    \n",
        "    print(imgs_A.shape, fake_B.shape, fake_A.shape)\n",
        "\n",
        "    gen_imgs = np.concatenate([imgs_A, fake_B, reconstr_A, imgs_B, fake_A, reconstr_B])\n",
        "\n",
        "    # Rescale images 0 - 1\n",
        "    gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "\n",
        "    titles = ['Original', 'Translated', 'Reconstructed']\n",
        "    fig, axs = plt.subplots(r, c)\n",
        "    cnt = 0\n",
        "    for i in range(r):\n",
        "      for j in range(c):\n",
        "        axs[i,j].imshow(gen_imgs[cnt])\n",
        "        axs[i, j].set_title(titles[j])\n",
        "        axs[i,j].axis('off')\n",
        "        cnt += 1\n",
        "    fig.savefig(self.output_img_path+\"/%s/%d_%d.png\" % (self.dataset_name, epoch, batch_i))\n",
        "    plt.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qlj4iELh6Jm_",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUJ0ftHt5jVC",
        "colab_type": "code",
        "outputId": "9ae36be0-1f5f-41d1-c04b-cc8d8c6f4430",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "output_img_path = '/Drive/My Drive/facegan-final'\n",
        "if not os.path.isdir(output_img_path):\n",
        "  os.makedirs(output_img_path)\n",
        "gan = CycleGAN(output_img_path=output_img_path)\n",
        "# gan.train(1)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Summary Discriminator:\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_25 (InputLayer)        (None, 256, 256, 3)       0         \n",
            "_________________________________________________________________\n",
            "d_h0_conv (Conv2D)           (None, 128, 128, 64)      3072      \n",
            "_________________________________________________________________\n",
            "lrelu (LeakyReLU)            (None, 128, 128, 64)      0         \n",
            "_________________________________________________________________\n",
            "d_h1_conv (Conv2D)           (None, 64, 64, 128)       131072    \n",
            "_________________________________________________________________\n",
            "d_lrelu1 (LeakyReLU)         (None, 64, 64, 128)       0         \n",
            "_________________________________________________________________\n",
            "d_bn1 (InstanceNormalization (None, 64, 64, 128)       2         \n",
            "_________________________________________________________________\n",
            "d_h2_conv (Conv2D)           (None, 32, 32, 256)       524288    \n",
            "_________________________________________________________________\n",
            "d_lrelu2 (LeakyReLU)         (None, 32, 32, 256)       0         \n",
            "_________________________________________________________________\n",
            "d_bn2 (InstanceNormalization (None, 32, 32, 256)       2         \n",
            "_________________________________________________________________\n",
            "d_h3_conv (Conv2D)           (None, 32, 32, 512)       2097152   \n",
            "_________________________________________________________________\n",
            "d_lrelu3 (LeakyReLU)         (None, 32, 32, 512)       0         \n",
            "_________________________________________________________________\n",
            "d_bn3 (InstanceNormalization (None, 32, 32, 512)       2         \n",
            "_________________________________________________________________\n",
            "d_h3_pred (Conv2D)           (None, 32, 32, 1)         8192      \n",
            "=================================================================\n",
            "Total params: 2,763,782\n",
            "Trainable params: 2,763,782\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Summary Generator:\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_27 (InputLayer)           (None, 256, 256, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lambda_177 (Lambda)             (None, 262, 262, 3)  0           input_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "g_e1_c (Conv2D)                 (None, 256, 256, 64) 9408        lambda_177[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "generatorg_e1_bn (InstanceNorma (None, 256, 256, 64) 2           g_e1_c[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "g_e2_c (Conv2D)                 (None, 128, 128, 128 73728       generatorg_e1_bn[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "generatorg_e2_bn (InstanceNorma (None, 128, 128, 128 2           g_e2_c[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "g_e3_c (Conv2D)                 (None, 64, 64, 256)  294912      generatorg_e2_bn[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "generatorg_e3_bn (InstanceNorma (None, 64, 64, 256)  2           g_e3_c[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lambda_178 (Lambda)             (None, 66, 66, 256)  0           generatorg_e3_bn[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "g_r1_c1 (Conv2D)                (None, 64, 64, 256)  589824      lambda_178[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "g_r1_bn1 (InstanceNormalization (None, 64, 64, 256)  2           g_r1_c1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_179 (Lambda)             (None, 66, 66, 256)  0           g_r1_bn1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "g_r1_c2 (Conv2D)                (None, 64, 64, 256)  589824      lambda_179[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "g_r1_bn2 (InstanceNormalization (None, 64, 64, 256)  2           g_r1_c2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "add_73 (Add)                    (None, 64, 64, 256)  0           g_r1_bn2[0][0]                   \n",
            "                                                                 generatorg_e3_bn[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "lambda_180 (Lambda)             (None, 66, 66, 256)  0           add_73[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "g_r2_c1 (Conv2D)                (None, 64, 64, 256)  589824      lambda_180[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "g_r2_bn1 (InstanceNormalization (None, 64, 64, 256)  2           g_r2_c1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_181 (Lambda)             (None, 66, 66, 256)  0           g_r2_bn1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "g_r2_c2 (Conv2D)                (None, 64, 64, 256)  589824      lambda_181[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "g_r2_bn2 (InstanceNormalization (None, 64, 64, 256)  2           g_r2_c2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "add_74 (Add)                    (None, 64, 64, 256)  0           g_r2_bn2[0][0]                   \n",
            "                                                                 add_73[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lambda_182 (Lambda)             (None, 66, 66, 256)  0           add_74[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "g_r3_c1 (Conv2D)                (None, 64, 64, 256)  589824      lambda_182[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "g_r3_bn1 (InstanceNormalization (None, 64, 64, 256)  2           g_r3_c1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_183 (Lambda)             (None, 66, 66, 256)  0           g_r3_bn1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "g_r3_c2 (Conv2D)                (None, 64, 64, 256)  589824      lambda_183[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "g_r3_bn2 (InstanceNormalization (None, 64, 64, 256)  2           g_r3_c2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "add_75 (Add)                    (None, 64, 64, 256)  0           g_r3_bn2[0][0]                   \n",
            "                                                                 add_74[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lambda_184 (Lambda)             (None, 66, 66, 256)  0           add_75[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "g_r4_c1 (Conv2D)                (None, 64, 64, 256)  589824      lambda_184[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "g_r4_bn1 (InstanceNormalization (None, 64, 64, 256)  2           g_r4_c1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_185 (Lambda)             (None, 66, 66, 256)  0           g_r4_bn1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "g_r4_c2 (Conv2D)                (None, 64, 64, 256)  589824      lambda_185[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "g_r4_bn2 (InstanceNormalization (None, 64, 64, 256)  2           g_r4_c2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "add_76 (Add)                    (None, 64, 64, 256)  0           g_r4_bn2[0][0]                   \n",
            "                                                                 add_75[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lambda_186 (Lambda)             (None, 66, 66, 256)  0           add_76[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "g_r5_c1 (Conv2D)                (None, 64, 64, 256)  589824      lambda_186[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "g_r5_bn1 (InstanceNormalization (None, 64, 64, 256)  2           g_r5_c1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_187 (Lambda)             (None, 66, 66, 256)  0           g_r5_bn1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "g_r5_c2 (Conv2D)                (None, 64, 64, 256)  589824      lambda_187[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "g_r5_bn2 (InstanceNormalization (None, 64, 64, 256)  2           g_r5_c2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "add_77 (Add)                    (None, 64, 64, 256)  0           g_r5_bn2[0][0]                   \n",
            "                                                                 add_76[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lambda_188 (Lambda)             (None, 66, 66, 256)  0           add_77[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "g_r6_c1 (Conv2D)                (None, 64, 64, 256)  589824      lambda_188[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "g_r6_bn1 (InstanceNormalization (None, 64, 64, 256)  2           g_r6_c1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_189 (Lambda)             (None, 66, 66, 256)  0           g_r6_bn1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "g_r6_c2 (Conv2D)                (None, 64, 64, 256)  589824      lambda_189[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "g_r6_bn2 (InstanceNormalization (None, 64, 64, 256)  2           g_r6_c2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "add_78 (Add)                    (None, 64, 64, 256)  0           g_r6_bn2[0][0]                   \n",
            "                                                                 add_77[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lambda_190 (Lambda)             (None, 66, 66, 256)  0           add_78[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "g_r7_c1 (Conv2D)                (None, 64, 64, 256)  589824      lambda_190[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "g_r7_bn1 (InstanceNormalization (None, 64, 64, 256)  2           g_r7_c1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_191 (Lambda)             (None, 66, 66, 256)  0           g_r7_bn1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "g_r7_c2 (Conv2D)                (None, 64, 64, 256)  589824      lambda_191[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "g_r7_bn2 (InstanceNormalization (None, 64, 64, 256)  2           g_r7_c2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "add_79 (Add)                    (None, 64, 64, 256)  0           g_r7_bn2[0][0]                   \n",
            "                                                                 add_78[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lambda_192 (Lambda)             (None, 66, 66, 256)  0           add_79[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "g_r8_c1 (Conv2D)                (None, 64, 64, 256)  589824      lambda_192[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "g_r8_bn1 (InstanceNormalization (None, 64, 64, 256)  2           g_r8_c1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_193 (Lambda)             (None, 66, 66, 256)  0           g_r8_bn1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "g_r8_c2 (Conv2D)                (None, 64, 64, 256)  589824      lambda_193[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "g_r8_bn2 (InstanceNormalization (None, 64, 64, 256)  2           g_r8_c2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "add_80 (Add)                    (None, 64, 64, 256)  0           g_r8_bn2[0][0]                   \n",
            "                                                                 add_79[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lambda_194 (Lambda)             (None, 66, 66, 256)  0           add_80[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "g_r9_c1 (Conv2D)                (None, 64, 64, 256)  589824      lambda_194[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "g_r9_bn1 (InstanceNormalization (None, 64, 64, 256)  2           g_r9_c1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_195 (Lambda)             (None, 66, 66, 256)  0           g_r9_bn1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "g_r9_c2 (Conv2D)                (None, 64, 64, 256)  589824      lambda_195[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "g_r9_bn2 (InstanceNormalization (None, 64, 64, 256)  2           g_r9_c2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "add_81 (Add)                    (None, 64, 64, 256)  0           g_r9_bn2[0][0]                   \n",
            "                                                                 add_80[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "g_d1_dc (Conv2DTranspose)       (None, 128, 128, 128 294912      add_81[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "g_d1_bn (InstanceNormalization) (None, 128, 128, 128 2           g_d1_dc[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_196 (Lambda)             (None, 128, 128, 128 0           g_d1_bn[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "g_d2_dc (Conv2DTranspose)       (None, 256, 256, 64) 73728       lambda_196[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "g_d2_bn (InstanceNormalization) (None, 256, 256, 64) 2           g_d2_dc[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_197 (Lambda)             (None, 256, 256, 64) 0           g_d2_bn[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_198 (Lambda)             (None, 262, 262, 64) 0           lambda_197[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "g_pred_c (Conv2D)               (None, 256, 256, 3)  9408        lambda_198[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 11,372,974\n",
            "Trainable params: 11,372,974\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Loading weights\n",
            "Done loading\n",
            "(1, 256, 256, 3) (1, 256, 256, 3) (1, 256, 256, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fv7oPVO0BgAs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}