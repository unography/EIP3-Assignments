{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EIP_GAN_CyclicInfoGAN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkFyGUM2iqM4",
        "colab_type": "code",
        "outputId": "82fdb534-fcae-40a9-cf85-d46818f881b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/Drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SZCYSed6TmM",
        "colab_type": "text"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKxrNUn-NWzD",
        "colab_type": "code",
        "outputId": "355d9d7e-c7b9-45d8-daed-f25b303c0982",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "source": [
        "!pip install git+https://www.github.com/keras-team/keras-contrib.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://www.github.com/keras-team/keras-contrib.git\n",
            "  Cloning https://www.github.com/keras-team/keras-contrib.git to /tmp/pip-req-build-7qft7omg\n",
            "  Running command git clone -q https://www.github.com/keras-team/keras-contrib.git /tmp/pip-req-build-7qft7omg\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from keras-contrib==2.0.8) (2.2.4)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.3.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.1.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (3.13)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.0.8)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.16.4)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.12.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (2.8.0)\n",
            "Building wheels for collected packages: keras-contrib\n",
            "  Building wheel for keras-contrib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-contrib: filename=keras_contrib-2.0.8-cp36-none-any.whl size=101066 sha256=4ffc8715e9466f1df130b30b3193afe520bf75b336d4420daf0d64f2767ef8a5\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-srw5x8if/wheels/11/27/c8/4ed56de7b55f4f61244e2dc6ef3cdbaff2692527a2ce6502ba\n",
            "Successfully built keras-contrib\n",
            "Installing collected packages: keras-contrib\n",
            "Successfully installed keras-contrib-2.0.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIHj5DbWNiC3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras_contrib.layers.normalization.instancenormalization import InstanceNormalization\n",
        "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Concatenate, Lambda, Add\n",
        "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
        "from keras.layers.convolutional import UpSampling2D, Conv2D, Conv2DTranspose\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.activations import relu, tanh\n",
        "from keras.models import Sequential, Model\n",
        "from keras.optimizers import Adam\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.layers import *\n",
        "from keras.layers.merge import *\n",
        "from keras import backend as K\n",
        "from glob import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime\n",
        "import scipy\n",
        "import scipy.misc\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow.contrib.slim as slim\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import copy\n",
        "import math\n",
        "import cv2\n",
        "import json\n",
        "\n",
        "np.random.seed(42)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6zisS0x6dIc",
        "colab_type": "text"
      },
      "source": [
        "## Get Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDGObZSs4xIC",
        "colab_type": "code",
        "outputId": "01cbe558-abba-4561-8fce-fb2ad7d0a548",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "GLASS_LABELS = dict()\n",
        "\n",
        "def download():\n",
        "  url = 'https://dl.dropboxusercontent.com/s/1i2h7orwm2cx8s0/UTKFace.tar.gz'\n",
        "  fpath = 'UTKFace.tar.gz'\n",
        "  filename = fpath.split('/')[-1]\n",
        "  if not os.path.isfile(fpath):\n",
        "    os.system(f'wget {url}')\n",
        "    os.system(f'tar xzf {filename}')\n",
        "  else:\n",
        "    print(\"Data already present\")\n",
        "    \n",
        "\n",
        "def copy_imgs_young(fpath, data_path):\n",
        "  low = 18\n",
        "  high = 25\n",
        "  final_path_train = data_path + \"/trainA\"\n",
        "  final_path_test = data_path + \"/testA\"\n",
        "  if not os.path.isdir(final_path_train):\n",
        "    os.makedirs(final_path_train)\n",
        "  if not os.path.isdir(final_path_test):\n",
        "    os.makedirs(final_path_test)\n",
        "  allowed_files = []\n",
        "  for fname in tqdm(glob(fpath+\"/*.jpg\")):\n",
        "    age = int(fname.split('/')[-1].split('_')[0])\n",
        "    if age >= low and age <= high:\n",
        "      allowed_files.append(fname)\n",
        "      \n",
        "  allowed_files.sort()\n",
        "  \n",
        "  train_len = int(0.8*len(allowed_files))\n",
        "  for fname in tqdm(allowed_files[:train_len]):\n",
        "      os.system(f'cp {fname} {final_path_train}/')\n",
        "  for fname in tqdm(allowed_files[train_len:]):\n",
        "      os.system(f'cp {fname} {final_path_test}/')\n",
        "      \n",
        "def copy_imgs_old(fpath, data_path):\n",
        "  low = 50\n",
        "  high = 60\n",
        "  final_path_train = data_path + \"/trainB\"\n",
        "  final_path_test = data_path + \"/testB\"\n",
        "  if not os.path.isdir(final_path_train):\n",
        "    os.makedirs(final_path_train)\n",
        "  if not os.path.isdir(final_path_test):\n",
        "    os.makedirs(final_path_test)\n",
        "  allowed_files = []\n",
        "  for fname in tqdm(glob(fpath+\"/*.jpg\")):\n",
        "    age = int(fname.split('/')[-1].split('_')[0])\n",
        "    if age >= low and age <= high:\n",
        "      allowed_files.append(fname)\n",
        "  \n",
        "  allowed_files.sort()\n",
        "  \n",
        "  train_len = int(0.8*len(allowed_files))\n",
        "  for fname in tqdm(allowed_files[:train_len]):\n",
        "      os.system(f'cp {fname} {final_path_train}/')\n",
        "  for fname in tqdm(allowed_files[train_len:]):\n",
        "      os.system(f'cp {fname} {final_path_test}/')\n",
        "      \n",
        "def fetch_glasses_labels():\n",
        "  global GLASS_LABELS\n",
        "  url = 'https://www.dl.dropboxusercontent.com/s/qryo4esy82er4ss/UTKFace_Glasses.json'\n",
        "  os.system(f'wget {url}')\n",
        "  d = json.load(open('UTKFace_Glasses.json'))\n",
        "  paths = ['datasets/faces/trainA', 'datasets/faces/trainB']\n",
        "  for folder in paths:\n",
        "    for fpath in glob(folder+\"/*.jpg\"):\n",
        "      fname = fpath.split(\"/\")[-1]\n",
        "      if fname in d:\n",
        "        GLASS_LABELS[fpath] = d[fname]\n",
        "  \n",
        "def prepare_dataset():\n",
        "  download()\n",
        "  copy_imgs_young('UTKFace', 'datasets/faces')\n",
        "  copy_imgs_old('UTKFace', 'datasets/faces')\n",
        "#   fetch_glasses_labels()\n",
        "  \n",
        "  \n",
        "prepare_dataset()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 23708/23708 [00:00<00:00, 703526.59it/s]\n",
            "100%|██████████| 2723/2723 [00:30<00:00, 89.39it/s]\n",
            "100%|██████████| 681/681 [00:07<00:00, 89.15it/s]\n",
            "100%|██████████| 23708/23708 [00:00<00:00, 795190.40it/s]\n",
            "100%|██████████| 2073/2073 [00:22<00:00, 90.27it/s]\n",
            "100%|██████████| 519/519 [00:05<00:00, 90.29it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0FXiELl1gUb",
        "colab_type": "code",
        "outputId": "2907c8d6-5fa2-4eeb-ef3c-3b03e03416c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(GLASS_LABELS)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3827"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20A0DxYP6PhM",
        "colab_type": "text"
      },
      "source": [
        "## Model declaration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Muel1elo49jj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DataLoader():\n",
        "  def __init__(self, dataset_name, img_res=(256, 256)):\n",
        "    self.dataset_name = dataset_name\n",
        "    self.img_res = img_res\n",
        "    self.dataset_root_path = \"datasets\"\n",
        "\n",
        "  def load_data(self, domain, batch_size=1, is_testing=False, img_res=(256, 256)):\n",
        "    data_type = \"train%s\" % domain if not is_testing else \"test%s\" % domain\n",
        "    path = glob('./datasets/%s/%s/*' % (self.dataset_name, data_type))\n",
        "\n",
        "    batch_images = np.random.choice(path, size=batch_size)\n",
        "\n",
        "    imgs = []\n",
        "    labels = []\n",
        "    for img_path in batch_images:\n",
        "      img = self.imread(img_path)\n",
        "      if not is_testing:\n",
        "        img = cv2.resize(img, img_res)\n",
        "\n",
        "        if np.random.random() > 0.5:\n",
        "          img = np.fliplr(img)\n",
        "      else:\n",
        "        img = cv2.resize(img, img_res)\n",
        "      imgs.append(img)\n",
        "      labels.append(self.get_label(img_path))\n",
        "\n",
        "    imgs = np.array(imgs)/127.5 - 1.\n",
        "\n",
        "    return imgs, labels\n",
        "\n",
        "  def load_batch(self, batch_size=1, is_testing=False, img_res=(256, 256)):\n",
        "    data_type = \"train\" if not is_testing else \"val\"\n",
        "    path_A = glob(f'./{self.dataset_root_path}/%s/%sA/*' % (self.dataset_name, data_type))\n",
        "    path_B = glob(f'./{self.dataset_root_path}/%s/%sB/*' % (self.dataset_name, data_type))\n",
        "\n",
        "    self.n_batches = int(min(len(path_A), len(path_B)) / batch_size)\n",
        "    total_samples = self.n_batches * batch_size\n",
        "\n",
        "    # Sample n_batches * batch_size from each path list so that model sees all\n",
        "    # samples from both domains\n",
        "    path_A = np.random.choice(path_A, total_samples, replace=False)\n",
        "    path_B = np.random.choice(path_B, total_samples, replace=False)\n",
        "\n",
        "    for i in range(self.n_batches-1):\n",
        "      batch_A = path_A[i*batch_size:(i+1)*batch_size]\n",
        "      batch_B = path_B[i*batch_size:(i+1)*batch_size]\n",
        "      imgs_A, imgs_B = [], []\n",
        "      labels_A, labels_B = [], []\n",
        "      for img_A, img_B in zip(batch_A, batch_B):\n",
        "        img_path_A = img_A\n",
        "        img_path_B = img_B\n",
        "        img_A = self.imread(img_A)\n",
        "        img_B = self.imread(img_B)\n",
        "\n",
        "        img_A = cv2.resize(img_A, img_res)\n",
        "        img_B = cv2.resize(img_B, img_res)\n",
        "\n",
        "        if not is_testing and np.random.random() > 0.5:\n",
        "            img_A = np.fliplr(img_A)\n",
        "            img_B = np.fliplr(img_B)\n",
        "\n",
        "        imgs_A.append(img_A)\n",
        "        imgs_B.append(img_B)\n",
        "        labels_A.append(self.get_label(img_path_A))\n",
        "        labels_B.append(self.get_label(img_path_B))\n",
        "\n",
        "      imgs_A = np.array(imgs_A)/127.5 - 1.\n",
        "      imgs_B = np.array(imgs_B)/127.5 - 1.\n",
        "\n",
        "      yield imgs_A, imgs_B, labels_A, labels_B\n",
        "  \n",
        "  def get_label(self, img_path):\n",
        "    gender = int(img_path.split('/')[-1].split('_')[1])\n",
        "    if gender == 0:  # Male\n",
        "      return 1\n",
        "    elif gender == 1:  # Female\n",
        "      return 2\n",
        "\n",
        "  def load_img(self, path, img_res=(256, 256)):\n",
        "    img = self.imread(path)\n",
        "    img = cv2.resize(img, img_res)\n",
        "    img = img/127.5 - 1.\n",
        "    return img[np.newaxis, :, :, :]\n",
        "\n",
        "  def imread(self, path):\n",
        "    img = cv2.imread(path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB).astype(np.float)\n",
        "    return img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UYoD7cCpgdY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CycleGAN():\n",
        "    def __init__(self, img_rows, img_cols, channels, save_path='/Drive/My Drive/facegan/train',\n",
        "                 output_img_path='images', c_path=None):\n",
        "        # Input shape\n",
        "        self.img_rows = img_rows\n",
        "        self.img_cols = img_cols\n",
        "        self.channels = channels\n",
        "        self.img_shape = (self.img_rows, self.img_rows, self.channels)\n",
        "\n",
        "        # Configure data loader\n",
        "        self.dataset_name = 'faces'\n",
        "        self.data_loader = DataLoader(dataset_name=self.dataset_name,\n",
        "                                      img_res=(self.img_rows, self.img_cols))\n",
        "\n",
        "        self.save_path = save_path\n",
        "        self.output_img_path = 'images'\n",
        "\n",
        "        # Calculate output shape of D (PatchGAN)\n",
        "        patch = int(self.img_rows / 2 ** 4)\n",
        "        patch = int(self.img_rows / 2 ** 4)\n",
        "        patch *= 2  # hack to get the shape 32,32,1. todo: check\n",
        "        self.disc_patch = (patch, patch, 1)\n",
        "\n",
        "        # Number of filters in the first layer of G and D\n",
        "        self.gf = 64\n",
        "        self.df = 64\n",
        "\n",
        "        # Loss weights\n",
        "        self.lambda_cycle = 10.0  # Cycle-consistency loss\n",
        "        self.lambda_id = 0.1 * self.lambda_cycle  # Identity loss\n",
        "\n",
        "        self.lr_init = 0.0002\n",
        "        self.epoch_step = 100\n",
        "\n",
        "        # InfoGAN classes - currently gender\n",
        "        self.num_classes = 2\n",
        "\n",
        "        optimizer = Adam(self.lr_init, 0.5)\n",
        "\n",
        "        # Build and compile the discriminators\n",
        "        self.d_A, self.d_Labels_A = self.build_discriminators()\n",
        "        self.d_B, self.d_Labels_B = self.build_discriminators()\n",
        "\n",
        "        print(\"Summary Discriminator - Labels:\")\n",
        "        print(self.d_Labels_A.summary())\n",
        "        \n",
        "        self.d_A.compile(loss='mse',\n",
        "                         optimizer=optimizer,\n",
        "                         metrics=['accuracy'])\n",
        "        self.d_B.compile(loss='mse',\n",
        "                         optimizer=optimizer,\n",
        "                         metrics=['accuracy'])\n",
        "        # Info-GAN\n",
        "        self.d_Labels_A.compile(loss=[self.mutual_info_loss],\n",
        "                                optimizer=optimizer,\n",
        "                                metrics=['accuracy'])\n",
        "        self.d_Labels_B.compile(loss=[self.mutual_info_loss],\n",
        "                                optimizer=optimizer,\n",
        "                                metrics=['accuracy'])\n",
        "\n",
        "        # -------------------------\n",
        "        # Construct Computational\n",
        "        #   Graph of Generators\n",
        "        # -------------------------\n",
        "\n",
        "        # Build the generators\n",
        "        self.g_AB = self.build_generator()\n",
        "        self.g_BA = self.build_generator()\n",
        "\n",
        "        print(\"Summary Generator:\")\n",
        "        print(self.g_AB.summary())\n",
        "\n",
        "        # Input images from both domains\n",
        "        # img_A = Input(shape=self.img_shape)\n",
        "        # img_B = Input(shape=self.img_shape)\n",
        "        img_A = Input(shape=(self.img_shape))\n",
        "        img_B = Input(shape=(self.img_shape))\n",
        "        label_A_inp = Input(shape=(1,), dtype='int32')\n",
        "        label_B_inp = Input(shape=(1,), dtype='int32')\n",
        "\n",
        "        # Translate images to the other domain\n",
        "        fake_B = self.g_AB([img_A, label_A_inp])\n",
        "        fake_A = self.g_BA([img_B, label_B_inp])\n",
        "        # Translate images back to original domain\n",
        "        reconstr_A = self.g_BA([fake_B, label_B_inp])\n",
        "        reconstr_B = self.g_AB([fake_A, label_A_inp])\n",
        "        # Identity mapping of images\n",
        "        img_A_id = self.g_BA([img_A, label_A_inp])\n",
        "        img_B_id = self.g_AB([img_B, label_B_inp])\n",
        "\n",
        "        # For the combined model we will only train the generators\n",
        "        self.d_A.trainable = False\n",
        "        self.d_B.trainable = False\n",
        "\n",
        "        # Discriminators determines validity of translated images\n",
        "        valid_A = self.d_A(fake_A)\n",
        "        valid_B = self.d_B(fake_B)\n",
        "\n",
        "        gan_outputs = [valid_A, valid_B,\n",
        "                       reconstr_A, reconstr_B,\n",
        "                       img_A_id, img_B_id]\n",
        "\n",
        "        gan_losses = ['mse', 'mse',\n",
        "                      'mae', 'mae',\n",
        "                      'mae', 'mae']\n",
        "        gan_loss_weights = [1, 1,\n",
        "                            self.lambda_cycle, self.lambda_cycle,\n",
        "                            self.lambda_id, self.lambda_id]\n",
        "\n",
        "        # ****** PERCEPT ****\n",
        "        #     self.model_perceptual = self.build_perceptual_model(input_shape=self.img_shape)\n",
        "\n",
        "        #     percept_A = self.model_perceptual([img_A])\n",
        "        #     percept_B = self.model_perceptual([img_B])\n",
        "        #     percept_reconstr_A = self.model_perceptual([reconstr_A])\n",
        "        #     percept_reconstr_B = self.model_perceptual([reconstr_B])\n",
        "        #     gan_outputs.extend([percept_A, percept_B,\n",
        "        #                        percept_reconstr_A, percept_reconstr_B,\n",
        "        #                        percept_reconstr_A, percept_reconstr_B])\n",
        "\n",
        "        #     gan_losses.extend(['mse', 'mse',\n",
        "        #                 'mse', 'mse',\n",
        "        #                 'mse', 'mse'])\n",
        "        #     gan_loss_weights.extend([self.lambda_id, self.lambda_id,\n",
        "        #                         self.lambda_id, self.lambda_id,\n",
        "        #                         self.lambda_id, self.lambda_id])\n",
        "        # ****** PERCEPT ****\n",
        "        label_A = self.d_Labels_A(fake_A)\n",
        "        label_B = self.d_Labels_B(fake_B)\n",
        "        label_A_reconstr = self.d_Labels_A(reconstr_A)\n",
        "        label_B_reconstr = self.d_Labels_B(reconstr_B)\n",
        "        gan_outputs.extend([\n",
        "            label_A, label_B,\n",
        "            label_A_reconstr, label_B_reconstr,\n",
        "            label_A_reconstr, label_B_reconstr\n",
        "        ])\n",
        "        gan_losses.extend([self.mutual_info_loss, self.mutual_info_loss,\n",
        "                           self.mutual_info_loss, self.mutual_info_loss,\n",
        "                           self.mutual_info_loss, self.mutual_info_loss])\n",
        "        gan_loss_weights.extend([self.lambda_id, self.lambda_id,\n",
        "                                 self.lambda_id, self.lambda_id,\n",
        "                                 self.lambda_id, self.lambda_id])\n",
        "\n",
        "        # Combined model trains generators to fool discriminators\n",
        "        self.combined = Model(inputs=[img_A, label_A_inp, img_B, label_B_inp],\n",
        "                              outputs=gan_outputs)\n",
        "        if c_path is not None:\n",
        "            print(f\"Loading weights: {c_path}\")\n",
        "            self.combined.load_weights(c_path)\n",
        "            \n",
        "            \n",
        "        self.combined.compile(loss=gan_losses,\n",
        "                              loss_weights=gan_loss_weights,\n",
        "                              optimizer=optimizer)\n",
        "\n",
        "    def mutual_info_loss(self, c, c_given_x):\n",
        "        \"\"\"The mutual information metric we aim to minimize (From InfoGAN)\"\"\"\n",
        "        eps = 1e-8\n",
        "        conditional_entropy = K.mean(- K.sum(K.log(c_given_x + eps) * c, axis=1))\n",
        "        entropy = K.mean(- K.sum(K.log(c + eps) * c, axis=1))\n",
        "\n",
        "        return conditional_entropy + entropy\n",
        "\n",
        "    def build_generator(self, name=\"generator\"):\n",
        "        gf_dim = self.gf\n",
        "        output_c_dim = self.channels\n",
        "\n",
        "        def conv2D(input_,\n",
        "                   output_dim,\n",
        "                   ks=4,\n",
        "                   s=2,\n",
        "                   stddev=0.02,\n",
        "                   padding='SAME',\n",
        "                   activation=False,\n",
        "                   instance_norm=False,\n",
        "                   name=\"conv2d\",\n",
        "                   act_name=\"relu\",\n",
        "                   activation_tanh=True,\n",
        "                   inst_norm_name=\"bn\"):\n",
        "\n",
        "            if activation_tanh:\n",
        "                x = Conv2D(\n",
        "                    output_dim,\n",
        "                    kernel_size=(ks, ks),\n",
        "                    strides=s,\n",
        "                    padding=padding,\n",
        "                    kernel_initializer=tf.truncated_normal_initializer(stddev=stddev),\n",
        "                    name=name,\n",
        "                    activation='tanh',\n",
        "                    use_bias=False)(input_)\n",
        "            elif activation:\n",
        "                x = Conv2D(\n",
        "                    output_dim,\n",
        "                    kernel_size=(ks, ks),\n",
        "                    strides=s,\n",
        "                    padding=padding,\n",
        "                    kernel_initializer=tf.truncated_normal_initializer(stddev=stddev),\n",
        "                    name=name,\n",
        "                    activation='relu',\n",
        "                    use_bias=False)(input_)\n",
        "            else:\n",
        "                x = Conv2D(\n",
        "                    output_dim,\n",
        "                    kernel_size=(ks, ks),\n",
        "                    strides=s,\n",
        "                    padding=padding,\n",
        "                    kernel_initializer=tf.truncated_normal_initializer(stddev=stddev),\n",
        "                    name=name,\n",
        "                    use_bias=False)(input_)\n",
        "            if instance_norm:\n",
        "                x = InstanceNormalization(name=inst_norm_name)(x)\n",
        "\n",
        "            return x\n",
        "\n",
        "        def deconv2d(input_, output_dim, ks=4, s=2, stddev=0.02, name=\"deconv2d\"):\n",
        "            x = Conv2DTranspose(\n",
        "                output_dim,\n",
        "                kernel_size=(ks, ks),\n",
        "                strides=s,\n",
        "                padding='SAME',\n",
        "                kernel_initializer=tf.truncated_normal_initializer(stddev=stddev),\n",
        "                name=name,\n",
        "                use_bias=False)(input_)\n",
        "\n",
        "            return x\n",
        "\n",
        "        def residule_block(x, dim, ks=3, s=1, name='res'):\n",
        "            p = int((ks - 1) / 2)\n",
        "            y = Lambda(lambda lx: tf.pad(lx, [[0, 0], [p, p], [p, p], [0, 0]], \"REFLECT\"))(x)\n",
        "            y = conv2D(y, dim, ks=ks, s=s, padding=\"VALID\", name=name + \"_c1\", activation=True, instance_norm=True,\n",
        "                       inst_norm_name=name + \"_bn1\")\n",
        "            y = Lambda(lambda x: tf.pad(x, [[0, 0], [p, p], [p, p], [0, 0]], \"REFLECT\"))(y)\n",
        "            y = conv2D(y, dim, ks=ks, s=s, padding=\"VALID\", name=name + \"_c2\", activation=False, instance_norm=True,\n",
        "                       inst_norm_name=name + \"_bn2\")\n",
        "            a = Add()([y, x])\n",
        "            return a  # 1/2을 안해도 되나??? 뒤에 노말라이즈해서 상관없는건가....\n",
        "\n",
        "        # Justin Johnson's model from https://github.com/jcjohnson/fast-neural-style/\n",
        "        # The network with 9 blocks consists of: c7s1-32, d64, d128, R128, R128, R128,\n",
        "        # R128, R128, R128, R128, R128, R128, u64, u32, c7s1-3\n",
        "\n",
        "        # inp = Input(shape=self.img_shape)\n",
        "        \n",
        "        img_inp = Input(shape=(self.img_shape))\n",
        "        inp_label = Input(shape=(1,), dtype='int32')\n",
        "       \n",
        "        label_embedding = Flatten()(Embedding(num_classes, (self.img_rows*self.img_cols*self.channels))(inp_label))\n",
        "        label_embedding = Reshape((self.img_rows,self.img_cols,self.channels))(label_embedding)\n",
        "\n",
        "        # inp = Multiply()([img_inp, label_embedding])\n",
        "        inp = multiply([img_inp, label_embedding])\n",
        "        \n",
        "\n",
        "        c0 = Lambda(lambda x: tf.pad(x, [[0, 0], [3, 3], [3, 3], [0, 0]], \"REFLECT\"))(inp)\n",
        "\n",
        "        c1 = conv2D(c0, gf_dim, ks=7, s=1, padding=\"VALID\", name=\"g_e1_c\", activation=True, instance_norm=True,\n",
        "                    inst_norm_name=name + \"g_e1_bn\", act_name=\"g_e1_relu\")\n",
        "        c2 = conv2D(c1, gf_dim * 2, ks=3, s=2, name=\"g_e2_c\", activation=True, instance_norm=True,\n",
        "                    inst_norm_name=name + \"g_e2_bn\", act_name=\"g_e2_relu\")\n",
        "        c3 = conv2D(c2, gf_dim * 4, ks=3, s=2, name=\"g_e3_c\", activation=True, instance_norm=True,\n",
        "                    inst_norm_name=name + \"g_e3_bn\", act_name=\"g_e3_relu\")  # 64x64\n",
        "\n",
        "        # define G network with 9 resnet blocks\n",
        "        # 총 cnn 18층.\n",
        "        r1 = residule_block(c3, gf_dim * 4, name='g_r1')\n",
        "        r2 = residule_block(r1, gf_dim * 4, name='g_r2')\n",
        "        r3 = residule_block(r2, gf_dim * 4, name='g_r3')\n",
        "        r4 = residule_block(r3, gf_dim * 4, name='g_r4')\n",
        "        r5 = residule_block(r4, gf_dim * 4, name='g_r5')\n",
        "        r6 = residule_block(r5, gf_dim * 4, name='g_r6')\n",
        "        r7 = residule_block(r6, gf_dim * 4, name='g_r7')\n",
        "        r8 = residule_block(r7, gf_dim * 4, name='g_r8')\n",
        "        r9 = residule_block(r8, gf_dim * 4, name='g_r9')\n",
        "\n",
        "        d1 = deconv2d(r9, gf_dim * 2, 3, 2, name='g_d1_dc')\n",
        "        d1 = InstanceNormalization(name='g_d1_bn')(d1)\n",
        "        d1 = Lambda(lambda x: relu(x))(d1)\n",
        "\n",
        "        d2 = deconv2d(d1, gf_dim, 3, 2, name='g_d2_dc')\n",
        "        d2 = InstanceNormalization(name='g_d2_bn')(d2)\n",
        "        d2 = Lambda(lambda x: relu(x))(d2)\n",
        "\n",
        "        d2 = Lambda(lambda x: tf.pad(x, [[0, 0], [3, 3], [3, 3], [0, 0]], \"REFLECT\"))(d2)\n",
        "\n",
        "        pred = conv2D(d2, output_c_dim, ks=7, s=1, padding=\"VALID\", name=\"g_pred_c\", activation=False,\n",
        "                      instance_norm=False, activation_tanh=True)\n",
        "        \n",
        "        return Model([img_inp, inp_label], pred)\n",
        "\n",
        "    def build_perceptual_model(self, input_shape, trainable=False, pop=True):\n",
        "        # import ResNet50 pretrained on imagenet\n",
        "        model = ResNet50(include_top=False, weights='imagenet', input_shape=input_shape)\n",
        "        if pop == True:\n",
        "            model.layers.pop()  # pop pooling layer\n",
        "            model.layers.pop()  # pop last activation layer\n",
        "\n",
        "        for layer in model.layers:\n",
        "            layer.trainable = trainable\n",
        "\n",
        "        #         print('Resnet50 for Perceptual loss:')\n",
        "        #         model.summary()\n",
        "        return model\n",
        "\n",
        "    def build_discriminators(self, name=\"discriminator\"):\n",
        "        df_dim = self.df\n",
        "\n",
        "        def conv2D(input_,\n",
        "                   output_dim,\n",
        "                   ks=4,\n",
        "                   s=2,\n",
        "                   stddev=0.02,\n",
        "                   padding='SAME',\n",
        "                   activation=False,\n",
        "                   instance_norm=False,\n",
        "                   name=\"conv2d\",\n",
        "                   act_name=\"lrelu\",\n",
        "                   inst_norm_name=\"bn\"):\n",
        "\n",
        "            x = Conv2D(\n",
        "                output_dim,\n",
        "                kernel_size=(ks, ks),\n",
        "                strides=s,\n",
        "                padding=padding,\n",
        "                kernel_initializer=tf.truncated_normal_initializer(stddev=stddev),\n",
        "                name=name,\n",
        "                use_bias=False)(input_)\n",
        "            if activation:\n",
        "                x = LeakyReLU(alpha=0.2, name=act_name)(x)\n",
        "            if instance_norm:\n",
        "                x = InstanceNormalization(name=inst_norm_name)(x)\n",
        "\n",
        "            return x\n",
        "\n",
        "        inp = Input(shape=self.img_shape)\n",
        "        h0 = conv2D(inp, df_dim, name='d_h0_conv', activation=True)\n",
        "        # h0 = lrelu(conv2d(image, df_dim, name='d_h0_conv'))\n",
        "        # h0 is (128 x 128 x self.df_dim)\n",
        "\n",
        "        h1 = conv2D(h0, df_dim * 2, name='d_h1_conv', activation=True, instance_norm=True, inst_norm_name='d_bn1',\n",
        "                    act_name='d_lrelu1')\n",
        "        # h1 = lrelu(instance_norm(conv2d(h0, df_dim*2, name='d_h1_conv'), 'd_bn1'))\n",
        "        # h1 is (64 x 64 x self.df_dim*2)\n",
        "\n",
        "        h2 = conv2D(h1, df_dim * 4, name='d_h2_conv', activation=True, instance_norm=True, inst_norm_name='d_bn2',\n",
        "                    act_name='d_lrelu2')\n",
        "        # h2 = lrelu(instance_norm(conv2d(h1, df_dim*4, name='d_h2_conv'), 'd_bn2'))\n",
        "        # h2 is (32x 32 x self.df_dim*4)\n",
        "\n",
        "        h3 = conv2D(h2, df_dim * 8, name='d_h3_conv', s=1, activation=True, instance_norm=True, inst_norm_name='d_bn3',\n",
        "                    act_name='d_lrelu3')\n",
        "        # h3 = lrelu(instance_norm(conv2d(h2, df_dim*8, s=1, name='d_h3_conv'), 'd_bn3'))\n",
        "        # h3 is (32 x 32 x self.df_dim*8)\n",
        "\n",
        "        h4 = conv2D(h3, 1, name='d_h3_pred', s=1, activation=False, instance_norm=False)\n",
        "        # h4 = conv2d(h3, 1, s=1, name='d_h3_pred')\n",
        "        # h4 is (32 x 32 x 1)\n",
        "\n",
        "        # Recognition\n",
        "        print(\"h4\", h4.shape)\n",
        "        label = Dense(128, activation='relu')(h4)\n",
        "        label = GlobalAveragePooling2D()(label)\n",
        "        print(\"lab\", label.shape)\n",
        "        label = Dense(self.num_classes, activation='softmax')(label)\n",
        "        print(\"lab\", label.shape)\n",
        "\n",
        "        return Model(inp, h4), Model(inp, label)\n",
        "\n",
        "    def train(self, epochs, batch_size=1, sample_interval=500, init_epoch=0):\n",
        "\n",
        "        start_time = datetime.datetime.now()\n",
        "\n",
        "        # Adversarial loss ground truths\n",
        "        valid = np.ones((batch_size,) + self.disc_patch)\n",
        "        fake = np.zeros((batch_size,) + self.disc_patch)\n",
        "\n",
        "        for epoch in range(init_epoch, epochs):\n",
        "            lr = self.lr_init if epoch < self.epoch_step else self.lr_init * (self.epoch - epoch) / (\n",
        "                    self.epoch - self.epoch_step)  # lr이 작아짐. 100에폭이 지나면.\n",
        "            for batch_i, (imgs_A, imgs_B, labels_A, labels_B) in enumerate(\n",
        "                    self.data_loader.load_batch(batch_size, img_res=(self.img_rows, self.img_cols))):\n",
        "\n",
        "                K.set_value(self.d_A.optimizer.lr, lr)\n",
        "                K.set_value(self.d_B.optimizer.lr, lr)\n",
        "                K.set_value(self.combined.optimizer.lr, lr)\n",
        "\n",
        "                # ----------------------\n",
        "                #  Train Discriminators\n",
        "                # ----------------------\n",
        "\n",
        "                # Translate images to opposite domain\n",
        "                labels_A = np.array(labels_A).reshape(-1, 1)\n",
        "                labels_B = np.array(labels_B).reshape(-1, 1)\n",
        "                imgs_A_gen_input = [imgs_A, labels_A]\n",
        "                imgs_B_gen_input = [imgs_B, labels_B]\n",
        "\n",
        "                fake_B = self.g_AB.predict(imgs_A_gen_input)\n",
        "                fake_A = self.g_BA.predict(imgs_B_gen_input)\n",
        "\n",
        "                # Train the discriminators (original images = real / translated = Fake)\n",
        "                dA_loss_real = self.d_A.train_on_batch(imgs_A, valid)\n",
        "                dA_loss_fake = self.d_A.train_on_batch(fake_A, fake)\n",
        "                dA_loss = 0.5 * np.add(dA_loss_real, dA_loss_fake)\n",
        "\n",
        "                dB_loss_real = self.d_B.train_on_batch(imgs_B, valid)\n",
        "                dB_loss_fake = self.d_B.train_on_batch(fake_B, fake)\n",
        "                dB_loss = 0.5 * np.add(dB_loss_real, dB_loss_fake)\n",
        "\n",
        "                # Total disciminator loss\n",
        "                d_loss = 0.5 * np.add(dA_loss, dB_loss)\n",
        "\n",
        "                # ------------------\n",
        "                #  Train Generators\n",
        "                # ------------------\n",
        "\n",
        "                gan_train_outputs = [valid, valid,\n",
        "                                     imgs_A, imgs_B,\n",
        "                                     imgs_A, imgs_B]\n",
        "\n",
        "                # ****** PERCEPT ****\n",
        "                #         percept_A_train = self.model_perceptual.predict(imgs_A)\n",
        "                #         percept_B_train = self.model_perceptual.predict(imgs_B)\n",
        "                #         percept_fake_A_train = self.model_perceptual.predict(fake_A)\n",
        "                #         percept_fake_B_train = self.model_perceptual.predict(fake_B)\n",
        "                #         gan_train_outputs.extend([percept_fake_B_train, percept_fake_A_train,\n",
        "                #                        percept_fake_A_train, percept_fake_B_train,\n",
        "                #                        percept_A_train, percept_B_train])\n",
        "                # ****** PERCEPT ****\n",
        "                label_A = self.d_Labels_A.predict(imgs_A)\n",
        "                label_B = self.d_Labels_B.predict(imgs_B)\n",
        "                label_A_reconstr = self.d_Labels_A.predict(fake_A)\n",
        "                label_B_reconstr = self.d_Labels_B.predict(fake_B)\n",
        "                gan_train_outputs.extend([label_B_reconstr, label_A_reconstr,\n",
        "                                          label_A_reconstr, label_B_reconstr,\n",
        "                                          label_A, label_B])\n",
        "\n",
        "                # Train the generators\n",
        "\n",
        "                g_loss = self.combined.train_on_batch([imgs_A_gen_input[0],imgs_A_gen_input[1], imgs_B_gen_input[0], imgs_B_gen_input[1]],\n",
        "                                                      gan_train_outputs)\n",
        "\n",
        "                elapsed_time = datetime.datetime.now() - start_time\n",
        "\n",
        "                loss_index = 6\n",
        "\n",
        "                if batch_i % 100 == 0:\n",
        "                    # Plot the progress\n",
        "                    #           print (\"[Epoch %d/%d] [Batch %d/%d] [D loss: %f, acc: %3d%%] [G loss: %05f, adv: %05f, recon: %05f, id: %05f] time: %s \" \\\n",
        "                    #                                       % ( epoch, epochs,\n",
        "                    #                                         batch_i, self.data_loader.n_batches,\n",
        "                    #                                         d_loss[0], 100*d_loss[1],\n",
        "                    #                                         g_loss[0],\n",
        "                    #                                         np.mean(g_loss[1:3]),\n",
        "                    #                                         np.mean(g_loss[3:5]),\n",
        "                    #                                         np.mean(g_loss[5:6]),\n",
        "                    #                                         elapsed_time))\n",
        "                    # ****** PERCEPT ****\n",
        "                    print(\n",
        "                        \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f, acc: %3d%%] [G loss: %05f, adv: %05f, recon: %05f, id: %05f, per_fB: %05f, per_fA: %05f, per_fArB: %05f, per_fBrA: %05f, per_rBrA: %05f, per_rBrB: %05f] time: %s \" \\\n",
        "                        % (epoch, epochs,\n",
        "                           batch_i, self.data_loader.n_batches,\n",
        "                           d_loss[0], 100 * d_loss[1],\n",
        "                           g_loss[0],\n",
        "                           np.mean(g_loss[1:3]),\n",
        "                           np.mean(g_loss[3:5]),\n",
        "                           np.mean(g_loss[5:6]),\n",
        "                           np.mean(g_loss[6]),\n",
        "                           np.mean(g_loss[7]),\n",
        "                           np.mean(g_loss[8]),\n",
        "                           np.mean(g_loss[9]),\n",
        "                           np.mean(g_loss[10]),\n",
        "                           np.mean(g_loss[11]),\n",
        "                           elapsed_time))\n",
        "                    # ****** PERCEPT ****\n",
        "\n",
        "                # If at save interval => save generated image samples\n",
        "                if batch_i % sample_interval == 0:\n",
        "                    self.sample_images(epoch, batch_i)\n",
        "                    self.save_model(epoch)\n",
        "\n",
        "    def save_model(self, epoch):\n",
        "        print(\"Saving model now\")\n",
        "        if not os.path.isdir(self.save_path):\n",
        "            os.makedirs(self.save_path)\n",
        "        # for further training - save with\n",
        "        self.combined.save_weights(self.save_path + '/%s-%d.h5' % (self.dataset_name, epoch))\n",
        "\n",
        "        # reload with\n",
        "        # self.combined.load_weights('train/%s-%d.h5' % (self.dataset_name, epoch))\n",
        "\n",
        "        # to generate images - save with\n",
        "        self.g_AB.save_weights(self.save_path + '/%s-AB-%d.h5' % (self.dataset_name, epoch))\n",
        "        self.g_BA.save_weights(self.save_path + '/%s-BA-%d.h5' % (self.dataset_name, epoch))\n",
        "\n",
        "        # load with\n",
        "        # self.g_AB.load_weights('train/%s-AB-%d.h5' % (self.dataset_name, epoch))\n",
        "        # self.g_BA.load_weights('train/%s-BA-%d.h5' % (self.dataset_name, epoch))\n",
        "\n",
        "    def parse_predicted_labels(self, labels):\n",
        "      parsed = []\n",
        "      for i, d in enumerate(labels):\n",
        "        parsed.append(np.argmax(d) + 1)\n",
        "      \n",
        "      return np.array(parsed)\n",
        "      \n",
        "    def sample_images(self, epoch, batch_i):\n",
        "        os.makedirs(self.output_img_path + '/%s' % self.dataset_name, exist_ok=True)\n",
        "        r, c = 2, 3\n",
        "\n",
        "        imgs_A, labels_A = self.data_loader.load_data(domain=\"A\", batch_size=1, is_testing=True,\n",
        "                                            img_res=(self.img_rows, self.img_cols))\n",
        "        imgs_B, labels_B = self.data_loader.load_data(domain=\"B\", batch_size=1, is_testing=True,\n",
        "                                            img_res=(self.img_rows, self.img_cols))\n",
        "\n",
        "        # Demo (for GIF)\n",
        "        # imgs_A = self.data_loader.load_img('datasets/apple2orange/testA/n07740461_1541.jpg')\n",
        "        # imgs_B = self.data_loader.load_img('datasets/apple2orange/testB/n07749192_4241.jpg')\n",
        "\n",
        "        # Translate images to the other domain\n",
        "        labels_A = np.array(labels_A).reshape(-1, 1)\n",
        "        labels_B = np.array(labels_B).reshape(-1, 1)\n",
        "        imgs_A_gen_input = [imgs_A, labels_A]\n",
        "        imgs_B_gen_input = [imgs_B, labels_B]\n",
        "        \n",
        "        fake_B = self.g_AB.predict(imgs_A_gen_input)\n",
        "        fake_A = self.g_BA.predict(imgs_B_gen_input)\n",
        "        fake_labels_A = self.d_Labels_A.predict(fake_A)\n",
        "        fake_labels_B = self.d_Labels_B.predict(fake_B)\n",
        "        fake_labels_A = self.parse_predicted_labels(fake_labels_A).reshape(-1,1)\n",
        "        fake_labels_B = self.parse_predicted_labels(fake_labels_A).reshape(-1,1)\n",
        "        \n",
        "        print(\"fake_labels_B.shape\", fake_labels_B.shape)\n",
        "        print(\"fake_labels\", fake_labels_B)\n",
        "        \n",
        "        # Translate back to original domain\n",
        "        fake_gen_input_A = [fake_A, fake_labels_A]\n",
        "        fake_gen_input_B = [fake_B, fake_labels_B]\n",
        "        reconstr_A = self.g_BA.predict(fake_gen_input_B)\n",
        "        reconstr_B = self.g_AB.predict(fake_gen_input_A)\n",
        "\n",
        "        gen_imgs = np.concatenate([imgs_A, fake_B, reconstr_A, imgs_B, fake_A, reconstr_B])\n",
        "\n",
        "        # Rescale images 0 - 1\n",
        "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "\n",
        "        titles = ['Original', 'Translated', 'Reconstructed']\n",
        "        fig, axs = plt.subplots(r, c)\n",
        "        cnt = 0\n",
        "        for i in range(r):\n",
        "            for j in range(c):\n",
        "                axs[i, j].imshow(gen_imgs[cnt])\n",
        "                axs[i, j].set_title(titles[j])\n",
        "                axs[i, j].axis('off')\n",
        "                cnt += 1\n",
        "        fig.savefig(self.output_img_path + \"/%s/%d_%d.png\" % (self.dataset_name, epoch, batch_i))\n",
        "        plt.close()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qlj4iELh6Jm_",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUJ0ftHt5jVC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gan = CycleGAN(img_rows=128,img_cols=128,channels=3,save_path='/Drive/My Drive/facegan/train',output_img_path='images',c_path=None)\n",
        "gan.train(1, init_epoch=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPdWGK53_Eq_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7I0UvUztr0l8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}